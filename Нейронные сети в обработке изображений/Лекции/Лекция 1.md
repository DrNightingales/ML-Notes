- Введение в терминологию ML
- [[Линейная регрессия]] и [[Логистическая регрессия]]
- [[метод k ближайших соседей]]
## Введение
### Типы задач ML
1. [[Supervised learning]]
2. [[Unsupervised learning]]
3. [[Semi-supervised learning]]
4. [[ Weakly supervised learning]]
5. [[Reinforcement learning]]
6. [[ Active learning]]
7. И др.
![[Pasted image 20240910165005.png]]
### ML в задачах обработки изображений
- Image enhancement
	- denoise
	- deringing (эффект Гиббса)
	- deblurring
- Image Classification
- Object detection
- Segmentation
	- Semantic
	- Object
### [[Параметры|Параметр]] и [[Гиперпараметры|Гиперпараметр]]
### [[Классификация]] vs [[Регрессия]] 
### Подходы к обучению
- [[Model-based learning]]
- [[Instance-base learning]]
### Типы обучения
- [[Deep learning]]
- [[Shallow learning]]
### Формализация
Алгоритм обучается на [[Опыт|опыте E]] относительно [[Класс задач|класс задач T]] и [[Мера качества(метрика)|Мера качества(метрика)]], если мера качества P на  классе задач T растет с ростом E

### Матрица плана **X**
Строки - объекты, столбцы - признаки

### Некоторые термины ML
- Generalization - способность модели предсказывать результат на новых данных
- Training error - мера ошибки, применяемая для обучающего набора
- Generalization error - мера ошибки для контрольного набора данных
Обучающий и тестовые наборы должны быть независимыми и одинаково распределенными, но в реальности это может быть не так
Улучшить модель можно:
1. уменьшив ошибку обучения
2. сократив разрыв между ошибками на обучающем и тестовом наборе данных
### Переобучение (overfitting)
![[Pasted image 20240910172935.png]]

Overfitting:
- Модель слишком сложная
- Модель неверно обучена на имеющихся данных
Underfitting:
- Модель слишком простая
[[Емкость(capacity) модели]]

## Итого
- Representation
- Evaluation
- Optimization



